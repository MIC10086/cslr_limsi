{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSLR model tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we give examples on how to train and use our CSLR model, on two datasets: Dicta-Sign-LSF-v2 and NCSLGR. These datasets contain the following annotations:\n",
    "\n",
    "### DictaSign (all binary except for fls)\n",
    "* fls (categorical, glosses are integers)\n",
    "* PT, PT_PRO1, PT_PRO2, PT_PRO3, PT_LOC, PT_DET, PT_LBUOY, PT_BUOY\n",
    "* DS, DSA, DSG, DSL, DSM, DSS, DST, DSX\n",
    "* FBUOY\n",
    "* N\n",
    "* FS\n",
    "\n",
    "### NCSLGR (all binary)\n",
    "* other\n",
    "* lexical_with_ns_not_fs\n",
    "* fingerspelling, fingerspelled_loan_signs\n",
    "* IX_1p, IX_2p, IX_3p, IX_loc\n",
    "* POSS, SELF\n",
    "* gesture\n",
    "* part_indef\n",
    "* DCL, LCL, SCL, BCL, ICL, BPCL, PCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.models.data_utils import *\n",
    "from src.models.model_utils import *\n",
    "from src.models.train_model import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A single binary output straight from the annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model aimed at recognizing pointing signs on DictaSign ('PT'), with 2 possible values (0/1), weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 420)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 100, 200)          252200    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 110)          112640    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 110)          73040     \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 100, 2)            222       \n",
      "=================================================================\n",
      "Total params: 438,102\n",
      "Trainable params: 438,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = get_model(['PT'],[2],[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us select videos 0 to 69 for training, 70 to 93 for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent : ../\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/DictaSign/features_HS.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4e01a40fb482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                         \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                         \u001b[0mvideo_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                         from_notebook=True)\n\u001b[0m\u001b[1;32m      7\u001b[0m features_1_valid, annot_1_valid = get_data_concatenated('DictaSign',\n\u001b[1;32m      8\u001b[0m                                                         \u001b[0;34m'mixed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/cslr_limsi/src/models/data_utils.py\u001b[0m in \u001b[0;36mget_data_concatenated\u001b[0;34m(corpus, output_form, output_names_final, output_categories_or_names_original, output_assemble, features_dict, preloaded_features, preloaded_annotations, video_indices, separation, from_notebook)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreloaded_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0mpreloaded_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_notebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreloaded_annotations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_form\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mixed'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/cslr_limsi/src/models/data_utils.py\u001b[0m in \u001b[0;36mget_features_videos\u001b[0;34m(corpus, features_dict, video_indices, from_notebook)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mkey_features_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_features_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey_features_number\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mkey_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'data/processed/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mindex_vid_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvid_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cslr_models/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/processed/DictaSign/features_HS.npy'"
     ]
    }
   ],
   "source": [
    "features_1_train, annot_1_train = get_data_concatenated('DictaSign',\n",
    "                                                        'mixed',\n",
    "                                                        ['PT'],\n",
    "                                                        [[1]],\n",
    "                                                        video_indices=np.arange(0,70),\n",
    "                                                        from_notebook=True)\n",
    "features_1_valid, annot_1_valid = get_data_concatenated('DictaSign',\n",
    "                                                        'mixed',\n",
    "                                                        ['PT'],\n",
    "                                                        [[1]],\n",
    "                                                        video_indices=np.arange(70,94),\n",
    "                                                        from_notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
